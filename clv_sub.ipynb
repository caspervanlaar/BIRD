{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "START = time.time()\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "tf.experimental.numpy.experimental_enable_numpy_behavior()\n",
    "\n",
    "TERMINATE_TIME = START + 5300\n",
    "\n",
    "# Load the trained model (h5 format)\n",
    "trained_model = tf.keras.models.load_model('/kaggle/input/yamnwave/other/default/1/yamnet_species_classifier.h5')\n",
    "\n",
    "# Load YAMNet model from TensorFlow Hub\n",
    "yamnet_model_handle = \"https://tfhub.dev/google/yamnet/1\"\n",
    "yamnet_model = hub.load(yamnet_model_handle)\n",
    "\n",
    "# Load sample submission and taxonomy\n",
    "primary_labels = pd.read_csv('/kaggle/input/birdclef-2025/sample_submission.csv').columns[1:].to_list()\n",
    "primary_labels_indices = range(len(primary_labels))\n",
    "primary_labels_map = dict(zip(primary_labels, primary_labels_indices))\n",
    "\n",
    "taxonomy = pd.read_csv('/kaggle/input/birdclef-2025/taxonomy.csv', index_col='common_name')['primary_label']\n",
    "taxonomy_map = taxonomy.map(primary_labels_map)\n",
    "common_names = taxonomy.index.to_list()\n",
    "\n",
    "# Assuming your model's labels are similar to the primary labels, or you have a mapping\n",
    "bc_labels = primary_labels  # Or load from your model's metadata if available\n",
    "bc_labels_indices = range(len(bc_labels))\n",
    "primary_labels_map_bc = dict(zip(bc_labels, bc_labels_indices))\n",
    "birdclassifier_last = len(bc_labels)\n",
    "birdclassifier_indices = [primary_labels_map_bc[pl] if pl in primary_labels else birdclassifier_last for pl in primary_labels]\n",
    "\n",
    "total_predicted_species = len(primary_labels) # Assuming your model can predict all.\n",
    "print(f'Note: we can predict {total_predicted_species} species only!')\n",
    "\n",
    "# Get all the data files\n",
    "def get_oggs():\n",
    "    if len(glob.glob('/kaggle/input/birdclef-2025/test_soundscapes/*.ogg')) > 0:\n",
    "        oggs = glob.glob('/kaggle/input/birdclef-2025/test_soundscapes/*.ogg')\n",
    "    else:\n",
    "        oggs = sorted(glob.glob('/kaggle/input/birdclef-2025/train_soundscapes/*.ogg'))\n",
    "    return [(n, ogg, re.search(r'/([^/]+)\\.ogg$', ogg).group(1)) for n, ogg in enumerate(oggs)]\n",
    "\n",
    "oggs = get_oggs()\n",
    "\n",
    "# Process the files in threads\n",
    "def bvc_result(ogg):\n",
    "    _, fname, ss_id = ogg\n",
    "    sr = 32_000\n",
    "\n",
    "    #print(f'{ss_id}')\n",
    "    row_ids = [f'{ss_id}_{n}' for n in range(5, 65, 5)]\n",
    "\n",
    "    if time.time() > TERMINATE_TIME:\n",
    "        return row_ids, -1000 * np.ones((12, len(primary_labels)))\n",
    "\n",
    "    try:\n",
    "        data, _ = librosa.load(fname, sr=sr)\n",
    "        embeddings = []\n",
    "        for start_time in range(0, len(data), 5 * sr):\n",
    "            end_time = start_time + 5 * sr\n",
    "            segment = data[start_time:end_time]\n",
    "            if len(segment) < 5 * sr:\n",
    "                segment = np.pad(segment, (0, 5 * sr - len(segment)))\n",
    "            _, embedding, _ = yamnet_model(segment)\n",
    "            embeddings.append(embedding.numpy().mean(axis=0))\n",
    "        embeddings = np.array(embeddings)\n",
    "\n",
    "        model_outputs = trained_model.predict(embeddings)\n",
    "        model_outputs = tf.pad(model_outputs, tf.constant([[0, 0], [0, 1]]))\n",
    "        result = model_outputs[:, birdclassifier_indices]\n",
    "        return row_ids, result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ss_id}: {e}\")\n",
    "        return row_ids, -1000 * np.ones((12, len(primary_labels)))\n",
    "\n",
    "row_ids = []\n",
    "result = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    for ogg_row_ids, ogg_result in executor.map(bvc_result, oggs):\n",
    "        row_ids += ogg_row_ids\n",
    "        result.append(ogg_result)\n",
    "\n",
    "submission = pd.DataFrame(np.concatenate(result), columns=primary_labels)\n",
    "submission['row_id'] = row_ids\n",
    "submission = submission[['row_id'] + primary_labels]\n",
    "\n",
    "# Write CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Display submission DataFrame\n",
    "display(submission.head(20))\n",
    "display(submission.tail(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIRD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
